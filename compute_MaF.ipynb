{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff86c2d0",
   "metadata": {},
   "source": [
    "Trabajo basado en el paper **Multi-hop assortativities for network classification** por <em>Leonardo Gutierrez-Gomez</em> y <em>Jean-Charles Delvenne</em>, los datos de prueba se encuentran en [Nino Shervashidze](https://members.cbio.mines-paristech.fr/~nshervashidze/code/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad50215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import scipy.io\n",
    "import scipy.sparse.linalg as sp_linalg\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be8465",
   "metadata": {},
   "source": [
    "![eq_3_2](images/eq_3_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80ec7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ecuacion 3.2: calcula la autocovarianza de matrices para un camino aleatorio en un momento t\n",
    "#t: momento a calcular\n",
    "#P: matriz diagonal de distribución estacionaria\n",
    "#p: vector de distribución estacionaria\n",
    "#Me: matriz de markov\n",
    "def ro(t, P, p, Me):\n",
    "    return P * np.linalg.matrix_power(Me, t) - pi.transpose() * pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a1f16",
   "metadata": {},
   "source": [
    "![eq_3_3.png](images/eq_3_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6beb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ecuacion 3.3: covarianza del atributo v para los primeros t tiempos determinados por lag \n",
    "#v: atributos de cada nodo (arreglo de números)\n",
    "#cova: arreglo de covarianzas para los primeros t tiempos\n",
    "#lag: numero de tiempos a calcular\n",
    "def attr_cov(v, cova, lag):\n",
    "    cov = []\n",
    "    for t in range(lag+1):\n",
    "        cov.append((v.transpose() * cova[t] * v).tolist()[0][0])\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ea342",
   "metadata": {},
   "source": [
    "![eq_3_4.png](images/eq_3_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63989cb",
   "metadata": {},
   "source": [
    "![eq_3_6.png](images/eq_3_6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99763679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ecuacion 3.4: autocovarianza de variable categorica para los primeros t tiempos determinados por lag\n",
    "#Ecuacion 3.6: covarianza de variable categorica para los primeros t tiempos determinados por lag\n",
    "#Me: matriz de markov\n",
    "#p: vector de distribución estacionaria\n",
    "#P: matriz diagonal de distribución estacionaria\n",
    "#Ha: matriz one hot de la variable categorica\n",
    "#lag: numero de tiempos a calcular\n",
    "def covarianza(Me, p, P, Ha, lag): \n",
    "    # cov son las matrices de covarianza\n",
    "    # aut son las matrices de autocovarianza\n",
    "    # tr son las trazas de aut\n",
    "    cov = []\n",
    "    aut = []\n",
    "    tr = []\n",
    "    for t in range(lag +1):\n",
    "        cov.append(ro(t, P, p, Me))\n",
    "        aut.append(Ha.transpose() * cov[-1] * Ha)\n",
    "        tr.append(np.trace(aut[-1]))\n",
    "    return cov, aut, tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b13479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genera los atributos de distribucion estacionaria del grafo (vector y matriz diagonal)\n",
    "#graph: grafo de networkx\n",
    "#degrees: arreglo de grados\n",
    "def distribucion_estacionaria(graph, degrees):\n",
    "    m = len(graph.edges)\n",
    "    #pi es el vector de distribución estacionaria\n",
    "    p = degrees.transpose() / (2*m)\n",
    "    #PI es la matriz diagonal de distribución estacionaria\n",
    "    P = np.diag(p.tolist()[0])\n",
    "    return p, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412e8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula el promedio de los labels de los nodos\n",
    "#Ha: matriz one hot de la variable categorica\n",
    "#p: vector de distribución estacionaria\n",
    "def avg_feats(Ha, p):\n",
    "    avg = []\n",
    "    for i in range(len(Ha[0])):\n",
    "        avg.append(p * np.asmatrix(Ha[:,i]).transpose())\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13002f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#procesar los labels correspondientes al grafo, extrae los valores únicos y la codificación one hot\n",
    "def process_labels(lab):\n",
    "    unique = np.unique(lab.flatten())\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(unique.reshape(-1, 1))\n",
    "    oneHot = enc.transform(lab.reshape(-1, 1)).toarray()\n",
    "    return unique, oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69af493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genera el grafo junto con sus principales características \n",
    "#(matriz de adjacencia, arreglo de grados, matriz de grados, matriz de markov)\n",
    "#graph: representacion del grafo como matriz de adjacencia\n",
    "def generar_grafo(graph):\n",
    "    #Construccion del grafo\n",
    "    G = nx.from_numpy_matrix(graph)\n",
    "    #A es la matriz de adjacencia del grafo\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    #d es el arreglo de grados del grafo\n",
    "    d = A * np.ones((G.number_of_nodes(), 1))\n",
    "    #D es la matriz de grados diagonales\n",
    "    D = np.diag(d.transpose().tolist()[0])\n",
    "    #M es la matriz de markov del grafo\n",
    "    M = np.linalg.inv(D) * A\n",
    "    return G, A, d, M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2359aa45",
   "metadata": {},
   "source": [
    "![features](images/features.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "481e3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrae los features del grafo\n",
    "#graph: grafo de networkx\n",
    "#degrees: arreglo de grados\n",
    "#p: vector de distribución estacionaria\n",
    "#P: matriz diagonal de distribución estacionaria\n",
    "#lag: numero de tiempos a calcular\n",
    "#evec: eigenvectors principales\n",
    "#Me: matriz de markov\n",
    "#lab: labels de los nodos\n",
    "def extraccion_features(graph, degrees, p, P, lag, evec, Me, lab):\n",
    "    #feature1: multi-hop assortativities of node IDs, setting H = I in Eq. (3.6) for 0, 1, ... , t hops\n",
    "    #H es la matriz identidad del tamaño del grafo\n",
    "    H = np.identity(len(degrees))\n",
    "    cov, aut, res1 = covarianza(M, p, P, H, lag)\n",
    "    #feature2: average of first p dominant left eigenvector of M, that is {πv : v is a dominant eigenvector of M}\n",
    "    res2 = attr_cov(p.transpose(), cov, lag)\n",
    "    #feature3: multi-hop assortativities of the first p dominant left eigenvectors of M (Eq. 3.3) for 0, 1, ... , t hops\n",
    "    #segundo eigenvector\n",
    "    pi2 = np.asmatrix(evec[:,1]).transpose()\n",
    "    #normalizacion del segundo eigenvector\n",
    "    h2 = pi2/np.linalg.norm(pi2, 1)\n",
    "    res3 = attr_cov(h2, cov, lag)\n",
    "    #tercer eigenvector\n",
    "    pi3 = np.asmatrix(evec[:,2]).transpose()\n",
    "    #normalizacion del tercer eigenvector\n",
    "    h3 = pi3/np.linalg.norm(pi3, 1)\n",
    "    res4 = attr_cov(h3, cov, lag)\n",
    "    if node_labels:\n",
    "        #extraccion de labels del grafo\n",
    "        unique, categorias = process_labels(lab)\n",
    "        cov, aut, tr = covarianza(Me, p, P, categorias, lag)\n",
    "        #feature4: (If available) average of categorical metadata node attributes: {πhi : H = [h1, h2, ..hk ], 1 ≤ i ≤ k}\n",
    "        res5 = np.array([np.diag(i) for i in aut]).flatten()\n",
    "        #feature5: (If available) multi-hop assortativities of categorical metadata node attributes (Eq. 3.4) for 0, 1, ... , t hops\n",
    "        res6 = avg_feats(categorias, p)\n",
    "    #feature6: number of nodes\n",
    "    res9 = graph.number_of_nodes()\n",
    "    #feature7: number of edges\n",
    "    res7 = graph.number_of_edges()\n",
    "    r = {\n",
    "        #f1: asortatividad de multiples saltos de los nodos\n",
    "        0: res1,\n",
    "        #f2: asortatividad de multiples saltos del primer vector propio dominante\n",
    "        1: [i.real for i in res2],\n",
    "        #f3: asortatividad de multiples saltos del segundo vector propio dominante\n",
    "        2: [i.real for i in res3],\n",
    "        #f4: asortatividad de multiples saltos del tercer vector propio dominante\n",
    "        3: [i.real for i in res4]\n",
    "    }\n",
    "    if node_labels:\n",
    "        #f5: promedio de los atributos de los nodos\n",
    "        r[4] = res5\n",
    "        #f6: asortatividad de multiples saltos para los atributos de los nodos\n",
    "        r[5] = [el.tolist()[0][0] for el in res6]\n",
    "    #f7: numero de arcos\n",
    "    r[6] = res7\n",
    "    #f8: promedio del primer vector propio dominante\n",
    "    r[7] = (pi * pi.transpose()).tolist()[0][0]\n",
    "    #f9: numero de nodos\n",
    "    r[8] = res9\n",
    "    #f10: promedio del segundo vector propio\n",
    "    r[9] = (pi * pi2).tolist()[0][0].real\n",
    "    #f11: promedio del tercer vector propio\n",
    "    r[10] = (pi * pi3).tolist()[0][0].real\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7797f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guarda la informacion los features como una fila mas\n",
    "#t: arreglo de titulos base\n",
    "#features: features a agregar como nueva fila\n",
    "#idx: indice de la fila actual\n",
    "#d: mapa donde se almacenan los datos\n",
    "def guardar_fila(t, features, idx, d):\n",
    "    for title in range(len(t)):\n",
    "        #confirmar si el feature se calculo\n",
    "        if title in features:\n",
    "            #confirmar que si el feature debe ser iterado para guardar sus elementos\n",
    "            if type(features[title]) != float and type(features[title]) != int :\n",
    "                for j in range(len(features[title])):\n",
    "                    #generar titulo de la columna con el indice correspondiente\n",
    "                    key = t[title] + '_' + str(j)\n",
    "                    #si la columna no existe, se genera\n",
    "                    if not key in d:\n",
    "                        d[key] = []\n",
    "                    curr_size = len(d[key])\n",
    "                    #si la columna existe, pero no tiene los todas las filas, se llena de 0 los espacios entre la ultima fila y la actual\n",
    "                    if  curr_size < i - 1:\n",
    "                        d[key] = d[key] + [None for z in range(idx- curr_size)]\n",
    "                    d[key].append(features[title][j])\n",
    "            #si es un tipo primitivo, se guarda como es\n",
    "            else:\n",
    "                key = t[title]\n",
    "                #si la columna no existe, se genera\n",
    "                if not key in d:\n",
    "                    d[key] = []\n",
    "                d[key].append(features[title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69ee8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajustar los datos por si hay filas faltantes\n",
    "#d: mapa que contiene los datos\n",
    "#filas: numero esperado de filas\n",
    "def ajustar_datos(d, filas):\n",
    "    for key in d.keys():\n",
    "        curr_size = len(d[key])\n",
    "        #si hacen falta filas, se rellenan con 0\n",
    "        if  curr_size < filas:\n",
    "            d[key] = d[key] + [None for z in range(filas - curr_size)]\n",
    "        #print(curr_size, len(d[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd32da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['ID', 'pagerank', 'eigenvec_2nd_M', 'eigenvec_3rd_M', 'node_attribs', 'avg_node_labels', 'n_edges', 'avg_pi', 'avg_inv_pi', 'avg_eigenvec_2nd', 'avg_eigenvec_3rd']\n",
    "#nombre del dataset\n",
    "name = 'mutag'\n",
    "#si utilizar los labels de los nodos\n",
    "node_labels = True\n",
    "#numero de tiempos a calcular\n",
    "l = 3\n",
    "#numero de vectors propios a utilizar\n",
    "num_eig = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abdfe5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga del dataset\n",
    "dataset = scipy.io.loadmat('datasets/'+name+'.mat')\n",
    "names = list(dataset.keys())[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b5d07bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_0</th>\n",
       "      <th>ID_1</th>\n",
       "      <th>ID_2</th>\n",
       "      <th>ID_3</th>\n",
       "      <th>pagerank_0</th>\n",
       "      <th>pagerank_1</th>\n",
       "      <th>pagerank_2</th>\n",
       "      <th>pagerank_3</th>\n",
       "      <th>eigenvec_2nd_M_0</th>\n",
       "      <th>eigenvec_2nd_M_1</th>\n",
       "      <th>...</th>\n",
       "      <th>node_attribs_12</th>\n",
       "      <th>node_attribs_13</th>\n",
       "      <th>node_attribs_14</th>\n",
       "      <th>node_attribs_15</th>\n",
       "      <th>avg_node_labels_3</th>\n",
       "      <th>node_attribs_16</th>\n",
       "      <th>node_attribs_17</th>\n",
       "      <th>node_attribs_18</th>\n",
       "      <th>node_attribs_19</th>\n",
       "      <th>avg_node_labels_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953361</td>\n",
       "      <td>-0.046639</td>\n",
       "      <td>0.379287</td>\n",
       "      <td>-0.046639</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.954719</td>\n",
       "      <td>-0.045281</td>\n",
       "      <td>0.419005</td>\n",
       "      <td>-0.045281</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943182</td>\n",
       "      <td>-0.056818</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-0.056818</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953361</td>\n",
       "      <td>-0.046639</td>\n",
       "      <td>0.379287</td>\n",
       "      <td>-0.046639</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.936288</td>\n",
       "      <td>-0.063712</td>\n",
       "      <td>0.383657</td>\n",
       "      <td>-0.063712</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>-0.004048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.896694</td>\n",
       "      <td>-0.103306</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>-0.103306</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.902778</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>-0.008970</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.913265</td>\n",
       "      <td>-0.086735</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>-0.086735</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.915816</td>\n",
       "      <td>-0.084184</td>\n",
       "      <td>0.380102</td>\n",
       "      <td>-0.084184</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>-0.007022</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.908284</td>\n",
       "      <td>-0.091716</td>\n",
       "      <td>0.369822</td>\n",
       "      <td>-0.091716</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.011240</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID_0      ID_1      ID_2      ID_3  pagerank_0  pagerank_1  \\\n",
       "0    0.953361 -0.046639  0.379287 -0.046639    0.000111    0.000009   \n",
       "1    0.954719 -0.045281  0.419005 -0.045281    0.000182   -0.000069   \n",
       "2    0.943182 -0.056818  0.375000 -0.056818    0.000176   -0.000035   \n",
       "3    0.953361 -0.046639  0.379287 -0.046639    0.000111    0.000009   \n",
       "4    0.936288 -0.063712  0.383657 -0.063712    0.000242   -0.000013   \n",
       "..        ...       ...       ...       ...         ...         ...   \n",
       "183  0.896694 -0.103306  0.396694 -0.103306    0.000973   -0.000342   \n",
       "184  0.902778 -0.097222  0.402778 -0.097222    0.000965   -0.000482   \n",
       "185  0.913265 -0.086735  0.377551 -0.086735    0.000586   -0.000143   \n",
       "186  0.915816 -0.084184  0.380102 -0.084184    0.000475   -0.000072   \n",
       "187  0.908284 -0.091716  0.369822 -0.091716    0.000578   -0.000219   \n",
       "\n",
       "     pagerank_2  pagerank_3  eigenvec_2nd_M_0  eigenvec_2nd_M_1  ...  \\\n",
       "0      0.000039   -0.000003          0.002286         -0.002185  ...   \n",
       "1      0.000083   -0.000033          0.002222         -0.001841  ...   \n",
       "2      0.000070   -0.000026          0.000176         -0.000035  ...   \n",
       "3      0.000043   -0.000001          0.002286         -0.002185  ...   \n",
       "4      0.000096   -0.000020          0.004299         -0.004048  ...   \n",
       "..          ...         ...               ...               ...  ...   \n",
       "183    0.000285   -0.000143          0.015064          0.010308  ...   \n",
       "184    0.000338   -0.000249          0.010417         -0.008970  ...   \n",
       "185    0.000221   -0.000141          0.000586         -0.000143  ...   \n",
       "186    0.000171   -0.000092          0.007555         -0.007022  ...   \n",
       "187    0.000198   -0.000115          0.011240          0.008083  ...   \n",
       "\n",
       "     node_attribs_12  node_attribs_13  node_attribs_14  node_attribs_15  \\\n",
       "0                NaN              NaN              NaN              NaN   \n",
       "1                NaN              NaN              NaN              NaN   \n",
       "2                NaN              NaN              NaN              NaN   \n",
       "3                NaN              NaN              NaN              NaN   \n",
       "4                NaN              NaN              NaN              NaN   \n",
       "..               ...              ...              ...              ...   \n",
       "183              NaN              NaN              NaN              NaN   \n",
       "184              NaN              NaN              NaN              NaN   \n",
       "185              NaN              NaN              NaN              NaN   \n",
       "186              NaN              NaN              NaN              NaN   \n",
       "187              NaN              NaN              NaN              NaN   \n",
       "\n",
       "     avg_node_labels_3  node_attribs_16  node_attribs_17  node_attribs_18  \\\n",
       "0                  NaN              NaN              NaN              NaN   \n",
       "1                  NaN              NaN              NaN              NaN   \n",
       "2                  NaN              NaN              NaN              NaN   \n",
       "3                  NaN              NaN              NaN              NaN   \n",
       "4                  NaN              NaN              NaN              NaN   \n",
       "..                 ...              ...              ...              ...   \n",
       "183                NaN              NaN              NaN              NaN   \n",
       "184                NaN              NaN              NaN              NaN   \n",
       "185                NaN              NaN              NaN              NaN   \n",
       "186                NaN              NaN              NaN              NaN   \n",
       "187                NaN              NaN              NaN              NaN   \n",
       "\n",
       "     node_attribs_19  avg_node_labels_4  \n",
       "0                NaN                NaN  \n",
       "1                NaN                NaN  \n",
       "2                NaN                NaN  \n",
       "3                NaN                NaN  \n",
       "4                NaN                NaN  \n",
       "..               ...                ...  \n",
       "183              NaN                NaN  \n",
       "184              NaN                NaN  \n",
       "185              NaN                NaN  \n",
       "186              NaN                NaN  \n",
       "187              NaN                NaN  \n",
       "\n",
       "[188 rows x 46 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "df = None\n",
    "Graphs = dataset[names[1]][0]\n",
    "num_graphs = len(Graphs)\n",
    "for i in range(num_graphs):\n",
    "    #print('procesando grafo en posicion', i)\n",
    "    #labels de los nodos\n",
    "    labels = Graphs[i][1][0][0][0].flatten()\n",
    "    #total de nodos\n",
    "    total = len(Graphs[i])\n",
    "    #Construccion del grafo\n",
    "    G, A, d, M = generar_grafo(Graphs[i][0])\n",
    "    #calculo de distribucion estacionaria\n",
    "    pi, PI = distribucion_estacionaria(G, d)\n",
    "    #calculo de los primeros eigenvalues y egenvectors de mayor a menor magnitud\n",
    "    evalues, evectors = sp_linalg.eigs(M.transpose(), k = num_eig, which = 'LM')\n",
    "    r = extraccion_features(G, d, pi, PI, l, evectors, M, labels)\n",
    "    guardar_fila(titles, r, i, data)\n",
    "ajustar_datos(data, num_graphs)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd5c0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generar csv\n",
    "df.to_csv('features/' + name + '_features_py.csv', sep=',', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
